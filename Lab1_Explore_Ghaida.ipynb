{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a33c7492-b843-4823-87d8-b336608dcb3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plot\n",
    "import seaborn\n",
    "import re\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a48036fc-a9b1-43bf-b60f-3a9c639a4dc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configure how graphs will show up in this notebook\n",
    "%matplotlib inline\n",
    "seaborn.set_context('notebook', rc={'figure.figsize': (50, 50)}, font_scale=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4180a90d-5f50-45bf-8dc0-b2c9765b18a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1 µs, sys: 1e+03 ns, total: 2 µs\n",
      "Wall time: 6.2 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def load_embeddings(filename):\n",
    "    \"\"\"\n",
    "    Load a DataFrame from the generalized text format used by word2vec, GloVe,\n",
    "    fastText, and ConceptNet Numberbatch. The main point where they differ is\n",
    "    whether there is an initial line with the dimensions of the matrix.\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    rows = []\n",
    "    with open(filename, encoding='utf-8') as infile:\n",
    "        for i, line in enumerate(infile):\n",
    "            items = line.rstrip().split(' ')\n",
    "            if len(items) == 2:\n",
    "                # This is a header row giving the shape of the matrix\n",
    "                continue\n",
    "            labels.append(items[0])\n",
    "            values = np.array([float(x) for x in items[1:]], 'f')\n",
    "            rows.append(values)\n",
    "    \n",
    "    arr = np.vstack(rows)\n",
    "    return pd.DataFrame(arr, index=labels, dtype='f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc7c40f0-8e78-4ced-802f-81f4a10524e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/embeddings/Glove/glove.840B.300d.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m\n",
      "File \u001b[0;32m<timed exec>:9\u001b[0m, in \u001b[0;36mload_embeddings\u001b[0;34m(filename)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/embeddings/Glove/glove.840B.300d.txt'"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "glove_840B_embeddings = load_embeddings('data/embeddings/Glove/glove.840B.300d.txt')\n",
    "glove_840B_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85faa6f3-26a3-4067-882d-6b3094438147",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "glove_6B_300d_embeddings = load_embeddings('data/embeddings/Glove/glove.6B.300d.txt')\n",
    "glove_6B_300d_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20942ea8-5492-40a4-89f8-8a72f831ca27",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading word2vec\n",
    "from conceptnet5.vectors.formats import load_word2vec_bin\n",
    "w2v = load_word2vec_bin('large_data/word2vec-googlenews-300.bin.gz', nrows=2000000)\n",
    "\n",
    "# word2vec is case-sensitive, so case-fold its labels\n",
    "w2v.index = [label.casefold() for label in w2v.index]\n",
    "\n",
    "# Now we have duplicate labels, so drop the later (lower-frequency) occurrences of the same label\n",
    "w2v = w2v.reset_index().drop_duplicates(subset='index', keep='first').set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbc4db0-2ca1-4fce-859d-5831c1c2328e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lexicon(filename):\n",
    "    \"\"\"\n",
    "    Load a file from Bing Liu's sentiment lexicon\n",
    "    (https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html), containing\n",
    "    English words in Latin-1 encoding.\n",
    "    \n",
    "    One file contains a list of positive words, and the other contains\n",
    "    a list of negative words. The files contain comment lines starting\n",
    "    with ';' and blank lines, which should be skipped.\n",
    "    \"\"\"\n",
    "    lexicon = []\n",
    "    with open(filename, encoding='latin-1') as infile:\n",
    "        for line in infile:\n",
    "            line = line.rstrip()\n",
    "            if line and not line.startswith(';'):\n",
    "                lexicon.append(line)\n",
    "    return lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad68ecd-b179-40b3-bdee-5420403d8b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_words = load_lexicon('data/positive-words.txt')\n",
    "neg_words = load_lexicon('data/negative-words.txt')\n",
    "\n",
    "print(len(pos_words), len(neg_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b9dbc5-2509-4efd-a9da-9da9ccfc927b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "TOKEN_RE = re.compile(r\"\\w.*?\\b\")\n",
    "\n",
    "def vecs_to_sentiment(model, vecs):\n",
    "    # predict_log_proba gives the log probability for each class\n",
    "    predictions = model.predict_log_proba(vecs)\n",
    "\n",
    "    # To see an overall positive vs. negative classification in one number,\n",
    "    # we take the log probability of positive sentiment minus the log\n",
    "    # probability of negative sentiment.\n",
    "    # this is a logarithm of the max margin for the classifier, \n",
    "    # similar to odds ratio (but not exact) log(p_1/p_0) = log(p_1)-log(p_0)\n",
    "    return predictions[:, 1] - predictions[:, 0]\n",
    "\n",
    "\n",
    "def words_to_sentiment(model, embeddings, words):\n",
    "    vecs = embeddings.loc[embeddings.index.intersection(set(words))].dropna()\n",
    "    # vecs = embeddings.loc[words].dropna()\n",
    "    log_odds = vecs_to_sentiment(model, vecs)\n",
    "    return pd.DataFrame({'sentiment': log_odds}, index=vecs.index)\n",
    "    \n",
    "\n",
    "def text_to_sentiment(model, embeddings, text):\n",
    "    # tokenize the input phrase\n",
    "    tokens = [token.casefold() for token in TOKEN_RE.findall(text)]\n",
    "    # send each token separately into the embedding, then the classifier\n",
    "    sentiments = words_to_sentiment(model, embeddings, tokens)\n",
    "    return sentiments['sentiment'].mean() # return the mean for the classifier        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23ebd6d-de27-4d32-9456-1df19b2db232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def texts_to_sentiment(model, embeddings, texts):\n",
    "    sentiments = pd.DataFrame(columns=['sentiment'])\n",
    "    for text in texts:\n",
    "        sentiments= pd.concat([sentiments, pd.DataFrame.from_records([{'sentiment': text_to_sentiment(model, embeddings, text)}])])\n",
    "    return sentiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99b5a28-e915-43ef-bf56-e8c5810eb049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_sentiment_table(model, embeddings, group_data, isText=False):\n",
    "    frames = []\n",
    "    for group, name_list in sorted(group_data.items()):\n",
    "        lower_names = [name.lower() for name in name_list]\n",
    "        if isText:\n",
    "            sentiments = texts_to_sentiment(model, embeddings, lower_names)\n",
    "        else:\n",
    "            sentiments = words_to_sentiment(model, embeddings, lower_names)\n",
    "        sentiments['group'] = group\n",
    "        frames.append(sentiments)\n",
    "\n",
    "    # Put together the data we got from each ethnic group into one big table\n",
    "    return pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fc19d9-6aaa-4946-9385-f08dbb81edd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(embeddings, title = ''):\n",
    "    # get the positive and negative embeddings\n",
    "    pos_words_common = list(set(pos_words) & set(embeddings.index)) \n",
    "    neg_words_common = list(set(neg_words) & set(embeddings.index)) \n",
    "    pos_vectors = embeddings.loc[pos_words_common]\n",
    "    neg_vectors = embeddings.loc[neg_words_common]\n",
    "    vectors = pd.concat([pos_vectors, neg_vectors])\n",
    "    targets = np.array([1 for entry in pos_vectors.index] + [-1 for entry in neg_vectors.index])\n",
    "    labels = list(pos_vectors.index) + list(neg_vectors.index)\n",
    "\n",
    "    # split the data\n",
    "    train_vectors, test_vectors, train_targets, test_targets, train_labels, test_labels = \\\n",
    "        train_test_split(vectors, targets, labels, test_size=0.1, random_state=0)\n",
    "    \n",
    "    # train our model\n",
    "    model = SGDClassifier(loss='log_loss', random_state=0, max_iter=100)\n",
    "    model.fit(train_vectors, train_targets)\n",
    "    \n",
    "    # print out a goodness of fit\n",
    "    accuracy = accuracy_score(model.predict(test_vectors), test_targets)\n",
    "    print(\"Accuracy of sentiment: {:.2%}\".format(accuracy))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5fa8a5-7933-4acb-8b96-ba7e46624d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6B = train_model(glove_6B_300d_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69af631f-5777-4c0c-883f-9ab5b2ded55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_840B = train_model(glove_840B_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d13ae87-79a2-446d-84d2-b1fe184f74de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_w2v = train_model(w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a68c1d-bb94-4b48-8593-bd2edc01846f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender by Name. (2020). UCI Machine Learning Repository. https://doi.org/10.24432/C55G7X.\n",
    "\n",
    "gender_names = pd.read_csv(\"data/gender_bias_test_data/uci_gendered_names/name_gender_dataset.csv\")\n",
    "\n",
    "gender_names.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351b4199-549b-4763-9f0a-bb62624a7dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_f = gender_names[gender_names.Gender == 'F'].shape[0]\n",
    "num_m = gender_names[gender_names.Gender == 'M'].shape[0]\n",
    "\n",
    "print('There are {} female instants vs {} male instants'.format(num_f, num_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5354269-b78c-4a77-bc60-cbdfb3167405",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENDER_CAT_NAMES = {\n",
    "    'female': gender_names[gender_names.Gender == 'F'].iloc[:num_m].Name.values,\n",
    "    'male': gender_names[gender_names.Gender == 'M'].Name.values\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad0cc7b-ccc8-4d15-a8cd-55db72d19aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_sentiment(model, embeddings, group_data, isText=False, swarmPlot=True):\n",
    "    print(\"---- Get the sentiment table\")\n",
    "    # get the name table of different people's names and save embeddings\n",
    "    category_sentiments = category_sentiment_table(model, embeddings, group_data, isText)\n",
    "    \n",
    "    stats_params = []\n",
    "    for group in category_sentiments.group.unique():\n",
    "        stats_params.append(category_sentiments['sentiment'][category_sentiments['group'] == group])\n",
    "    \n",
    "    print(\"---- Calculate F_oneway\")\n",
    "    stats.f_oneway(*stats_params)\n",
    "    fstat,pval = stats.f_oneway(*stats_params)\n",
    "    print('F-statistic:',fstat,' With P-value:', pval)\n",
    "\n",
    "    # Show the results on a swarm plot, with a consistent Y-axis\n",
    "    matplotlib.pyplot.figure(figsize=(15,5))\n",
    "    matplotlib.pyplot.subplot(121)\n",
    "    plot = None\n",
    "    if swarmPlot:\n",
    "        plot = seaborn.swarmplot(x='group', y='sentiment', data=category_sentiments)\n",
    "    else:\n",
    "        plot = seaborn.violinplot(x='group', y='sentiment', data=category_sentiments)\n",
    "    plot.set_ylim([-10, 10])\n",
    "    matplotlib.pyplot.subplot(122)\n",
    "    plot = seaborn.barplot(x='group', y='sentiment', data=category_sentiments, capsize=.1)\n",
    "    matplotlib.pyplot.suptitle(\"hehe\", fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91dbeb5-660b-41ba-83b2-da37a602e4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_sentiment(model_840B ,glove_840B_embeddings, GENDER_CAT_NAMES, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3439fa78-30fd-42a5-8a61-7c9c676527bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_sentiment(model_w2v ,w2v, GENDER_CAT_NAMES, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7138d39f-18e8-4862-89c7-2ea05940fbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gendered Words: https://github.com/ecmonsen/gendered_words\n",
    "\n",
    "gendered_words = pd.read_json('data/gender_bias_test_data/gendred_words/gendred_words.json')\n",
    "\n",
    "gendered_words.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1efc8fa-7544-44f8-baa3-d86e8352df78",
   "metadata": {},
   "outputs": [],
   "source": [
    "gendered_words = gendered_words.drop('gender_map', axis=1)\n",
    "gendered_words = gendered_words.drop('wordnet_senseno', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4a5316-3f2b-4c72-8488-6305fb68b87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gendered_words.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641d9e5a-b874-43ae-bfff-ced8b51874c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_f_2 = gendered_words[gendered_words.gender == 'f'].shape[0]\n",
    "num_m_2 = gendered_words[gendered_words.gender == 'm'].shape[0]\n",
    "\n",
    "print('There are {} female instants vs {} male instants'.format(num_f_2, num_m_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2384ae9f-6d85-4e54-8cb2-3ebdbc776849",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENDER_CAT_NAMES_2 = {\n",
    "    'female': gendered_words[gendered_words.gender == 'f'].iloc[:num_f_2].word.values,\n",
    "    'male': gendered_words[gendered_words.gender == 'm'].iloc[:num_f_2].word.values\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bbd140-c648-4abd-8833-458036ec2a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_sentiment(model_840B ,glove_840B_embeddings, GENDER_CAT_NAMES_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b0e948-593e-4840-b574-dd9785795e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_sentiment(model_w2v ,w2v, GENDER_CAT_NAMES_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d575ba7f-d3ae-4819-924f-3f195985c22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Case study for gender bias translations\n",
    "# https://ai.google/static/documents/case-study-translate-gender-bias.pdf\n",
    "\n",
    "google_translation = pd.read_csv(\"data/gender_bias_test_data/google_translation_gender_bias/google_en_es_gender_bias.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1272e00-e92d-4e0a-9490-e45ebeb8f97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_translation.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26634368-0fda-4cd4-918a-a74015e28642",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_translation = google_translation.drop(\n",
    "    [\n",
    "        'sourceLanguage', 'targetLanguage', 'documentID', 'stringID',\n",
    "        'translatedText', 'entityName', 'sourceURL'\n",
    "    ],\n",
    "    axis=1)\n",
    "\n",
    "df['short_str'] = df['long_str'].str.slice(0,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646b0a28-f6f1-4403-a3fe-03ea563f4a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_translation.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded5d556-6049-4b08-94bc-041e0c5ecaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = google_translation.sourceText.str.len()\n",
    "plot.hist(lengths) \n",
    "plot.axis([0,550,0,800])\n",
    "plot.xlabel('Text Length')\n",
    "plot.ylabel('Count')\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60316b6-3320-4eb7-9107-b2b0d0d470cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Max length is {}\".format(max(lengths)))\n",
    "print(\"Min length is {}\".format(min(lengths)))\n",
    "print(\"Top 10 lengths: \", lengths.value_counts().nlargest(10).to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c8a798-4c5e-4fdf-9109-66ea1ba4d9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH_STR = 513\n",
    "# Truncate and padd sentences with zeros\n",
    "google_translation['short_str'] = google_translation['sourceText'].str.slice(0,MAX_LENGTH_STR).str.zfill(MAX_LENGTH_STR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d7f5b1-d1cc-4408-ad8d-42624042e3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_translation.perceivedGender.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711f0ed3-e248-47b6-b0f1-878d324ef216",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_f_3 = google_translation[google_translation.perceivedGender == 'Female'].shape[0]\n",
    "num_m_3 = google_translation[google_translation.perceivedGender == 'Male'].shape[0]\n",
    "\n",
    "print('There are {} female instants vs {} male instants'.format(num_f_3, num_m_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52b0a2d-adff-4967-a0b8-f69c5b5f6a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_SAMPLES = 100\n",
    "GENDER_CAT_NAMES_3 = {\n",
    "    'female': google_translation[google_translation.perceivedGender == 'Female'].sample(n=NUMBER_SAMPLES).short_str.values,\n",
    "    'male': google_translation[google_translation.perceivedGender == 'Male'].sample(n=NUMBER_SAMPLES).short_str.values\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442d2b9e-c365-4636-8e6d-218236873e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cat_sentiment(model_w2v ,w2v, GENDER_CAT_NAMES_3, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e03759-9cae-4d43-8a7f-7a27e57bb22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cat_sentiment(model_6B ,glove_6B_300d_embeddings, GENDER_CAT_NAMES_3, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b16bd03-2006-4579-9eda-cebcd18ea929",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cat_sentiment(model_840B ,glove_840B_embeddings, GENDER_CAT_NAMES_3, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bff3e5-6180-4d69-b7bd-65ff57fb6c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other Biases to look into:\n",
    "\n",
    "# religious\n",
    "# gender\n",
    "# ageism \n",
    "# \n",
    "\n",
    "# racial <- is probably the most obvious one"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
