{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d0b2c0a-d58c-4174-ad7f-c331438aae0e",
   "metadata": {},
   "source": [
    "# Lab 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8f26788-7a7b-47b6-ba95-7df96a273558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d05fd789-4b20-407f-8cf4-200278f575c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn\n",
    "import re\n",
    "import math\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as pyplot\n",
    "import scipy.stats as stats\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Dense, Input\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Layer, MultiHeadAttention, LayerNormalization, GlobalAveragePooling1D\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28529dce-21a3-4d11-a8e5-43dc365033e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version:  2.9.2\n",
      "Keras Version:  2.9.0\n",
      "System Version:  3.9.16 (main, Dec  7 2022, 01:11:51) \n",
      "[GCC 9.4.0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensorflow version: \", tf.__version__)\n",
    "print(\"Keras Version: \", keras.__version__)\n",
    "print(\"System Version: \", sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2a0032-cc3e-417a-b0d3-0ef52c62dd89",
   "metadata": {},
   "source": [
    "# Load ConceptNet Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e05dfa6-0872-45bc-9471-793a5f8fe185",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_LOCATIONS = {\n",
    "    \"NUMBER_BATCH\": \"/notebooks/data/embeddings/numberBatch/numberbatch-en-17.04b.txt\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34a5777a-00d1-4133-9ae8-2d6a20e4a23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *************************************************************************************************************************************************\n",
    "# Robyn Speer (2017) How to make a racist AI without really trying [source code]. https://blog.conceptnet.io/posts/2017/how-to-make-a-racist-ai-without-really-trying/\n",
    "# *************************************************************************************************************************************************\n",
    "def load_embeddings(filename):\n",
    "    \"\"\"\n",
    "    Load a DataFrame from the generalized text format used by word2vec, GloVe,\n",
    "    fastText, and ConceptNet Numberbatch. The main point where they differ is\n",
    "    whether there is an initial line with the dimensions of the matrix.\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    rows = []\n",
    "    with open(filename, encoding='utf-8') as infile:\n",
    "        for i, line in enumerate(infile):\n",
    "            items = line.rstrip().split(' ')\n",
    "            if len(items) == 2:\n",
    "                # This is a header row giving the shape of the matrix\n",
    "                continue\n",
    "            labels.append(items[0])\n",
    "            values = np.array([float(x) for x in items[1:]], 'f')\n",
    "            rows.append(values)\n",
    "    \n",
    "    arr = np.vstack(rows)\n",
    "    return pd.DataFrame(arr, index=labels, dtype='f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575c5317-6a21-4162-a37a-74203186916a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "number_batch_embedding = load_embeddings(EMBEDDING_LOCATIONS[\"NUMBER_BATCH\"])\n",
    "number_batch_embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd11831-09da-42a2-94f9-90663aa0bed0",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc51206-bae2-453d-99a1-5f3330fbd4a1",
   "metadata": {},
   "source": [
    "## IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52253115-4d35-4753-b2a8-e341adc37665",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
