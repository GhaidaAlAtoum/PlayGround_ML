{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the transformer on glove embeddings and test the religous biases with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(filename):\n",
    "    \"\"\"\n",
    "    Load a DataFrame from the generalized text format used by word2vec, GloVe,\n",
    "    fastText, and ConceptNet Numberbatch. The main point where they differ is\n",
    "    whether there is an initial line with the dimensions of the matrix.\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    rows = []\n",
    "    with open(filename, encoding='utf-8') as infile:\n",
    "        for i, line in enumerate(infile):\n",
    "            items = line.rstrip().split(' ')\n",
    "            if len(items) == 2:\n",
    "                # This is a header row giving the shape of the matrix\n",
    "                continue\n",
    "            labels.append(items[0])\n",
    "            values = np.array([float(x) for x in items[1:]], 'f')\n",
    "            rows.append(values)\n",
    "    \n",
    "    arr = np.vstack(rows)\n",
    "    return pd.DataFrame(arr, index=labels, dtype='f')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lexicon(filename):\n",
    "    \"\"\"\n",
    "    Load a file from Bing Liu's sentiment lexicon\n",
    "    (https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html), containing\n",
    "    English words in Latin-1 encoding.\n",
    "    \n",
    "    One file contains a list of positive words, and the other contains\n",
    "    a list of negative words. The files contain comment lines starting\n",
    "    with ';' and blank lines, which should be skipped.\n",
    "    \"\"\"\n",
    "    lexicon = []\n",
    "    with open(filename, encoding='latin-1') as infile:\n",
    "        for line in infile:\n",
    "            line = line.rstrip()\n",
    "            if line and not line.startswith(';'):\n",
    "                lexicon.append(line)\n",
    "    return lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_matrix(word_index, glove_embeddings, embedding_dim):\n",
    "    # Initialize the embedding matrix as a numpy array\n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))  # +1 for handling the zero padding\n",
    "    found_words = 0\n",
    "    \n",
    "    for word, i in word_index.items():\n",
    "        if word in glove_embeddings.index:\n",
    "            embedding_vector = glove_embeddings.loc[word].values\n",
    "            if embedding_vector is not None:\n",
    "                embedding_matrix[i] = embedding_vector\n",
    "                found_words += 1\n",
    "    \n",
    "    print(\"Embedding Shape:\", embedding_matrix.shape, \"\\n\",\n",
    "          \"Total words found:\", found_words, \"\\n\",\n",
    "          \"Percentage:\", 100 * found_words / len(word_index))\n",
    "    \n",
    "    return torch.tensor(embedding_matrix, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def filter_glove_embeddings(glove_embeddings, lexicon_words):\n",
    "    # Filter the GloVe embeddings to only include words present in the lexicon\n",
    "    filtered_embeddings = glove_embeddings.loc[glove_embeddings.index.intersection(lexicon_words)]\n",
    "    return filtered_embeddings\n",
    "\n",
    "# Now create the word_index from the filtered GloVe embeddings\n",
    "def create_word_index_from_filtered_embeddings(filtered_embeddings):\n",
    "    return {word: i+1 for i, word in enumerate(filtered_embeddings.index)}  # Start indexing from 1\n",
    "\n",
    "\n",
    "def custom_tokenize_and_create_word_index(glove_word_index, words, max_length):\n",
    "    # This function needs to be defined correctly.\n",
    "    # Assuming it's meant to tokenize words and return their indices.\n",
    "    # The placeholder below is just an example.\n",
    "    sequences = [glove_word_index.get(word, 0) for word in words]  # Tokenize words\n",
    "    return sequences  # This should be a list of integers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2196017, 300)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load GloVe embeddings as a DataFrame\n",
    "glove_840B_embeddings = load_embeddings('data/embeddings/glove.840B.300d.txt')\n",
    "glove_840B_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hu_liu_lexicon_to_training_dataset(pos_value=1, neg_value=-1):\n",
    "    pos_words = load_lexicon('data/lexicons/hu_liu_2004/positive-words.txt')\n",
    "    neg_words = load_lexicon('data/lexicons/hu_liu_2004/negative_words.txt')\n",
    "    print(\"Positive Words: \", len(pos_words), \"Negative Words: \", len(neg_words))\n",
    "    words = list(pos_words + neg_words)\n",
    "    targets = [1 for entry in pos_words] + [0 for entry in neg_words]\n",
    "    return words, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Words:  2007 Negative Words:  4783\n",
      "[1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Load the Hu and Liu lexicon\n",
    "pos_neg_lexicon_X_base, pos_neg_lexicon_Y_base = load_hu_liu_lexicon_to_training_dataset()\n",
    "print(pos_neg_lexicon_Y_base[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming pos_neg_lexicon_X_base contains all the unique words in your lexicon dataset\n",
    "lexicon_words = set(pos_neg_lexicon_X_base)  # Create a set of unique lexicon words\n",
    "filtered_glove_embeddings = filter_glove_embeddings(glove_840B_embeddings, lexicon_words)\n",
    "\n",
    "glove_word_index = create_word_index_from_filtered_embeddings(filtered_glove_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize lexicon words based on GloVe word_index\n",
    "pos_neg_lexicon_indices = custom_tokenize_and_create_word_index(glove_word_index, pos_neg_lexicon_X_base, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure pos_neg_lexicon_indices is a list of integers\n",
    "pos_neg_lexicon_X_tensor = torch.tensor(pos_neg_lexicon_indices, dtype=torch.long)\n",
    "# Convert the labels to a tensor. Ensure this matches your loss function's expected format\n",
    "pos_neg_lexicon_Y_tensor = torch.tensor(pos_neg_lexicon_Y_base, dtype=torch.long)  # For CrossEntropyLoss, use long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build the custom transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Shape: (6615, 300) \n",
      " Total words found: 6614 \n",
      " Percentage: 100.0\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'glove_word_index' is a dict mapping your dataset words to their indices in the filtered GloVe embeddings\n",
    "embedding_matrix = get_embedding_matrix(glove_word_index, filtered_glove_embeddings, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the embedding layer with the preloaded GloVe embeddings\n",
    "embedding_layer = nn.Embedding.from_pretrained(embedding_matrix, freeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "pos_neg_lexicon_X_train, pos_neg_lexicon_X_test, pos_neg_lexicon_Y_train, pos_neg_lexicon_Y_test = train_test_split(\n",
    "    pos_neg_lexicon_X_tensor,  # Removed unsqueeze if you're processing word indices as sequences\n",
    "    pos_neg_lexicon_Y_tensor,\n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming pos_neg_lexicon_Y_train and pos_neg_lexicon_Y_test are your original labels with -1 and 1\n",
    "# pos_neg_lexicon_Y_train_adjusted = (pos_neg_lexicon_Y_train + 1) // 2  # Maps -1 to 0, and 1 to 1\n",
    "# pos_neg_lexicon_Y_test_adjusted = (pos_neg_lexicon_Y_test + 1) // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5983,    0])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_neg_lexicon_X_test[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Define the Custom Transformer Model\n",
    "This model will include an embedding layer initialized with your preloaded GloVe embeddings, a transformer encoder layer to capture the context, and a final classifier layer to predict the sentiment based on the lexicon input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTransformerModel(nn.Module):\n",
    "    def __init__(self, embedding_matrix, num_classes, seq_length):\n",
    "        super(CustomTransformerModel, self).__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze=True)\n",
    "        \n",
    "        # Adjust the number of attention heads to be divisible by embedding dimension (300)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embedding_matrix.size(1), nhead=6, dropout=0.1)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=6)\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Linear(embedding_matrix.size(1), num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, seq_length]\n",
    "        \n",
    "        # Embedding\n",
    "        x = self.embedding(x)  # x: [batch_size, seq_length, embedding_dim]\n",
    "        \n",
    "        # Transformer expects [seq_length, batch_size, embedding_dim]\n",
    "        x = x.permute(1, 0, 2)\n",
    "        \n",
    "        # Transformer Encoder\n",
    "        x = self.transformer_encoder(x)\n",
    "        \n",
    "        # Pooling - Assuming global average pooling across the sequence\n",
    "        x = x.mean(dim=0)  # Correct pooling operation\n",
    "        \n",
    "        # Classifier\n",
    "        out = self.classifier(x)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTransformerModel(nn.Module):\n",
    "    def __init__(self, embedding_matrix, num_classes, seq_length, num_layers=6, num_heads=10, hidden_dim=512, dropout=0.1):\n",
    "        super(CustomTransformerModel, self).__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze=True)\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embedding_matrix.size(1),  # Use the size of the embedding dimension\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=hidden_dim,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        self.classifier = nn.Linear(embedding_matrix.size(1), num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.permute(1, 0, 2)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x.mean(dim=0)\n",
    "        out = self.classifier(x)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Initialize the Model\n",
    "Before initializing the model, ensure we have the embedding matrix ready as a tensor, which we prepared using the get_embedding_matrix function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ART_LEN = 1000\n",
    "NUM_CLASSES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2196017, 300])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tango.tew/miniconda3/envs/torch_env/lib/python3.8/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "model = CustomTransformerModel(embedding_matrix, NUM_CLASSES, MAX_ART_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Training Preparation\n",
    "Define your loss function, optimizer, and optionally, learning rate schedulers or any regularization techniques you wish to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Training Loop\n",
    "Implement the training loop, iterating over your dataset and updating the model's weights based on the loss calculated from its predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Data for PyTorch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LexiconDataset(Dataset):\n",
    "    def __init__(self, x_tensor, y_tensor):\n",
    "        self.x = x_tensor.unsqueeze(1)  # Add sequence dimension\n",
    "        self.y = y_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate the Dataset and DataLoader for Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32  # Adjust based on your computational resources\n",
    "\n",
    "# Training Dataset and DataLoader\n",
    "train_dataset = LexiconDataset(pos_neg_lexicon_X_train, pos_neg_lexicon_Y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Testing Dataset and DataLoader\n",
    "test_dataset = LexiconDataset(pos_neg_lexicon_X_test, pos_neg_lexicon_Y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unique(pos_neg_lexicon_Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ready to Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for inputs, labels in train_loader:\n",
    "    print(inputs.shape, labels.shape)\n",
    "    break  # Remove or comment this line after verifying the shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.9579605460166931\n",
      "Epoch 1, Loss: 2.8094124794006348\n",
      "Epoch 1, Loss: 1.3583800792694092\n",
      "Epoch 1, Loss: 4.47660493850708\n",
      "Epoch 1, Loss: 0.9096378684043884\n",
      "Epoch 1, Loss: 0.6781406402587891\n",
      "Epoch 1, Loss: 1.1215811967849731\n",
      "Epoch 1, Loss: 0.9326765537261963\n",
      "Epoch 1, Loss: 0.6447389721870422\n",
      "Epoch 1, Loss: 0.6945757269859314\n",
      "Epoch 1, Loss: 1.0672390460968018\n",
      "Epoch 1, Loss: 0.6439735889434814\n",
      "Epoch 1, Loss: 0.4922581613063812\n",
      "Epoch 1, Loss: 0.6471454501152039\n",
      "Epoch 1, Loss: 0.6697860360145569\n",
      "Epoch 1, Loss: 0.675388514995575\n",
      "Epoch 1, Loss: 0.5942237973213196\n",
      "Epoch 1, Loss: 0.4548320770263672\n",
      "Epoch 1, Loss: 0.9344602227210999\n",
      "Epoch 1, Loss: 0.573497474193573\n",
      "Epoch 1, Loss: 0.871665894985199\n",
      "Epoch 1, Loss: 0.5545620918273926\n",
      "Epoch 1, Loss: 0.7162260413169861\n",
      "Epoch 1, Loss: 0.7867313027381897\n",
      "Epoch 1, Loss: 0.6944659948348999\n",
      "Epoch 1, Loss: 0.5060985684394836\n",
      "Epoch 1, Loss: 0.5910044312477112\n",
      "Epoch 1, Loss: 0.661442756652832\n",
      "Epoch 1, Loss: 1.0735210180282593\n",
      "Epoch 1, Loss: 0.8114480376243591\n",
      "Epoch 1, Loss: 0.6490362882614136\n",
      "Epoch 1, Loss: 0.6915599703788757\n",
      "Epoch 1, Loss: 0.841903030872345\n",
      "Epoch 1, Loss: 0.7608290910720825\n",
      "Epoch 1, Loss: 0.6260198354721069\n",
      "Epoch 1, Loss: 0.7816169261932373\n",
      "Epoch 1, Loss: 0.6730832457542419\n",
      "Epoch 1, Loss: 0.6550961136817932\n",
      "Epoch 1, Loss: 0.2867642641067505\n",
      "Epoch 1, Loss: 0.7267246246337891\n",
      "Epoch 1, Loss: 0.6968227624893188\n",
      "Epoch 1, Loss: 0.6811678409576416\n",
      "Epoch 1, Loss: 0.774193525314331\n",
      "Epoch 1, Loss: 0.7112789154052734\n",
      "Epoch 1, Loss: 0.6041125059127808\n",
      "Epoch 1, Loss: 0.5746215581893921\n",
      "Epoch 1, Loss: 0.5988312363624573\n",
      "Epoch 1, Loss: 0.6392178535461426\n",
      "Epoch 1, Loss: 0.9445984959602356\n",
      "Epoch 1, Loss: 0.6207460761070251\n",
      "Epoch 1, Loss: 0.5796438455581665\n",
      "Epoch 1, Loss: 0.6334508061408997\n",
      "Epoch 1, Loss: 0.6849735379219055\n",
      "Epoch 1, Loss: 0.6601101756095886\n",
      "Epoch 1, Loss: 0.5110963582992554\n",
      "Epoch 1, Loss: 0.6942580938339233\n",
      "Epoch 1, Loss: 0.6033374667167664\n",
      "Epoch 1, Loss: 0.5389364361763\n",
      "Epoch 1, Loss: 0.7322161197662354\n",
      "Epoch 1, Loss: 0.6028596758842468\n",
      "Epoch 1, Loss: 0.630700945854187\n",
      "Epoch 1, Loss: 0.6845327019691467\n",
      "Epoch 1, Loss: 0.6968199014663696\n",
      "Epoch 1, Loss: 0.6836128234863281\n",
      "Epoch 1, Loss: 0.616205096244812\n",
      "Epoch 1, Loss: 0.5781192779541016\n",
      "Epoch 1, Loss: 0.4353668987751007\n",
      "Epoch 1, Loss: 0.5935659408569336\n",
      "Epoch 1, Loss: 0.5894784331321716\n",
      "Epoch 1, Loss: 0.5437827110290527\n",
      "Epoch 1, Loss: 0.7409672737121582\n",
      "Epoch 1, Loss: 0.7797636985778809\n",
      "Epoch 1, Loss: 0.7626656889915466\n",
      "Epoch 1, Loss: 0.8776288628578186\n",
      "Epoch 1, Loss: 0.6393214464187622\n",
      "Epoch 1, Loss: 0.7938817739486694\n",
      "Epoch 1, Loss: 0.7455891966819763\n",
      "Epoch 1, Loss: 0.48641878366470337\n",
      "Epoch 1, Loss: 0.7214394211769104\n",
      "Epoch 1, Loss: 0.6108056306838989\n",
      "Epoch 1, Loss: 0.6162756681442261\n",
      "Epoch 1, Loss: 0.6764192581176758\n",
      "Epoch 1, Loss: 0.6994214653968811\n",
      "Epoch 1, Loss: 0.6508461236953735\n",
      "Epoch 1, Loss: 0.6246111392974854\n",
      "Epoch 1, Loss: 0.5625468492507935\n",
      "Epoch 1, Loss: 0.9129769802093506\n",
      "Epoch 1, Loss: 0.5668622851371765\n",
      "Epoch 1, Loss: 0.6576806306838989\n",
      "Epoch 1, Loss: 0.6218733191490173\n",
      "Epoch 1, Loss: 0.6010463237762451\n",
      "Epoch 1, Loss: 0.5987473130226135\n",
      "Epoch 1, Loss: 0.6045807003974915\n",
      "Epoch 1, Loss: 0.642074704170227\n",
      "Epoch 1, Loss: 0.8720813989639282\n",
      "Epoch 1, Loss: 0.6987645030021667\n",
      "Epoch 1, Loss: 0.6708593368530273\n",
      "Epoch 1, Loss: 0.6955573558807373\n",
      "Epoch 1, Loss: 0.7177859544754028\n",
      "Epoch 1, Loss: 0.6478269100189209\n",
      "Epoch 1, Loss: 0.5234423875808716\n",
      "Epoch 1, Loss: 0.5408527851104736\n",
      "Epoch 1, Loss: 0.7235698103904724\n",
      "Epoch 1, Loss: 0.5507333874702454\n",
      "Epoch 1, Loss: 0.8808859586715698\n",
      "Epoch 1, Loss: 0.6865146160125732\n",
      "Epoch 1, Loss: 0.5317558646202087\n",
      "Epoch 1, Loss: 0.6645519137382507\n",
      "Epoch 1, Loss: 0.709271252155304\n",
      "Epoch 1, Loss: 0.6987552642822266\n",
      "Epoch 1, Loss: 0.5813700556755066\n",
      "Epoch 1, Loss: 0.7010542750358582\n",
      "Epoch 1, Loss: 0.5967936515808105\n",
      "Epoch 1, Loss: 0.4504565894603729\n",
      "Epoch 1, Loss: 0.5682786107063293\n",
      "Epoch 1, Loss: 0.8507221937179565\n",
      "Epoch 1, Loss: 0.6179937124252319\n",
      "Epoch 1, Loss: 0.6126496195793152\n",
      "Epoch 1, Loss: 0.672262966632843\n",
      "Epoch 1, Loss: 0.6933079957962036\n",
      "Epoch 1, Loss: 0.6602638363838196\n",
      "Epoch 1, Loss: 0.5122858285903931\n",
      "Epoch 1, Loss: 0.5397933721542358\n",
      "Epoch 1, Loss: 0.8743675947189331\n",
      "Epoch 1, Loss: 0.5193372368812561\n",
      "Epoch 1, Loss: 1.033344030380249\n",
      "Epoch 1, Loss: 0.7464234828948975\n",
      "Epoch 1, Loss: 0.6498627066612244\n",
      "Epoch 1, Loss: 0.7710518836975098\n",
      "Epoch 1, Loss: 0.7455412745475769\n",
      "Epoch 1, Loss: 0.6431734561920166\n",
      "Epoch 1, Loss: 0.6056642532348633\n",
      "Epoch 1, Loss: 0.5351982116699219\n",
      "Epoch 1, Loss: 0.8037256598472595\n",
      "Epoch 1, Loss: 0.5973420143127441\n",
      "Epoch 1, Loss: 0.7362969517707825\n",
      "Epoch 1, Loss: 0.7468785643577576\n",
      "Epoch 1, Loss: 0.6943176984786987\n",
      "Epoch 1, Loss: 0.6829562187194824\n",
      "Epoch 1, Loss: 0.7297559380531311\n",
      "Epoch 1, Loss: 0.7529470920562744\n",
      "Epoch 1, Loss: 0.6960113048553467\n",
      "Epoch 1, Loss: 0.7167895436286926\n",
      "Epoch 1, Loss: 0.53076171875\n",
      "Epoch 1, Loss: 0.7880051136016846\n",
      "Epoch 1, Loss: 0.5281079411506653\n",
      "Epoch 1, Loss: 0.5688063502311707\n",
      "Epoch 1, Loss: 0.7579087018966675\n",
      "Epoch 1, Loss: 0.6154823899269104\n",
      "Epoch 1, Loss: 0.6945358514785767\n",
      "Epoch 1, Loss: 0.6722350120544434\n",
      "Epoch 1, Loss: 0.6783139705657959\n",
      "Epoch 1, Loss: 0.7439538240432739\n",
      "Epoch 1, Loss: 0.6744128465652466\n",
      "Epoch 1, Loss: 0.6791772842407227\n",
      "Epoch 1, Loss: 0.5388277173042297\n",
      "Epoch 1, Loss: 0.7292656898498535\n",
      "Epoch 1, Loss: 0.7428476810455322\n",
      "Epoch 1, Loss: 0.6935753226280212\n",
      "Epoch 1, Loss: 0.7038892507553101\n",
      "Epoch 1, Loss: 0.5775083899497986\n",
      "Epoch 1, Loss: 0.652712345123291\n",
      "Epoch 1, Loss: 0.6536522507667542\n",
      "Epoch 1, Loss: 0.5994623899459839\n",
      "Epoch 1, Loss: 0.5967645645141602\n",
      "Epoch 1, Loss: 0.581916332244873\n",
      "Epoch 1, Loss: 0.6212486028671265\n",
      "Epoch 1, Loss: 0.7420374155044556\n",
      "Epoch 1, Loss: 0.49603888392448425\n",
      "Epoch 1, Loss: 0.7038901448249817\n",
      "Epoch 2, Loss: 0.7476106882095337\n",
      "Epoch 2, Loss: 0.7053830623626709\n",
      "Epoch 2, Loss: 0.644954264163971\n",
      "Epoch 2, Loss: 0.630564272403717\n",
      "Epoch 2, Loss: 0.6348318457603455\n",
      "Epoch 2, Loss: 0.6755715012550354\n",
      "Epoch 2, Loss: 0.6009317636489868\n",
      "Epoch 2, Loss: 0.638705313205719\n",
      "Epoch 2, Loss: 0.7456620931625366\n",
      "Epoch 2, Loss: 0.5664495229721069\n",
      "Epoch 2, Loss: 0.6203979253768921\n",
      "Epoch 2, Loss: 0.429106205701828\n",
      "Epoch 2, Loss: 0.5343319773674011\n",
      "Epoch 2, Loss: 0.6251437067985535\n",
      "Epoch 2, Loss: 0.6558230519294739\n",
      "Epoch 2, Loss: 0.5744112730026245\n",
      "Epoch 2, Loss: 0.44821351766586304\n",
      "Epoch 2, Loss: 0.7684633731842041\n",
      "Epoch 2, Loss: 0.5252888202667236\n",
      "Epoch 2, Loss: 0.6230751872062683\n",
      "Epoch 2, Loss: 0.7106994986534119\n",
      "Epoch 2, Loss: 0.6225407123565674\n",
      "Epoch 2, Loss: 0.6355357766151428\n",
      "Epoch 2, Loss: 0.5904862284660339\n",
      "Epoch 2, Loss: 0.5590181946754456\n",
      "Epoch 2, Loss: 0.6222544312477112\n",
      "Epoch 2, Loss: 0.6972846984863281\n",
      "Epoch 2, Loss: 0.6835131049156189\n",
      "Epoch 2, Loss: 0.7767137289047241\n",
      "Epoch 2, Loss: 0.562121570110321\n",
      "Epoch 2, Loss: 0.5609917044639587\n",
      "Epoch 2, Loss: 0.5649347901344299\n",
      "Epoch 2, Loss: 0.4947608411312103\n",
      "Epoch 2, Loss: 0.6723150610923767\n",
      "Epoch 2, Loss: 0.6478374004364014\n",
      "Epoch 2, Loss: 0.6930175423622131\n",
      "Epoch 2, Loss: 0.6777929067611694\n",
      "Epoch 2, Loss: 0.5748854279518127\n",
      "Epoch 2, Loss: 0.5804096460342407\n",
      "Epoch 2, Loss: 0.580344557762146\n",
      "Epoch 2, Loss: 0.6191211342811584\n",
      "Epoch 2, Loss: 0.6162896156311035\n",
      "Epoch 2, Loss: 0.5625872015953064\n",
      "Epoch 2, Loss: 0.6339297890663147\n",
      "Epoch 2, Loss: 0.6031758189201355\n",
      "Epoch 2, Loss: 0.4897426664829254\n",
      "Epoch 2, Loss: 0.6507540941238403\n",
      "Epoch 2, Loss: 0.7595617175102234\n",
      "Epoch 2, Loss: 0.6896718144416809\n",
      "Epoch 2, Loss: 0.5951748490333557\n",
      "Epoch 2, Loss: 0.6047753095626831\n",
      "Epoch 2, Loss: 0.6826316118240356\n",
      "Epoch 2, Loss: 0.6056632399559021\n",
      "Epoch 2, Loss: 0.5895931124687195\n",
      "Epoch 2, Loss: 0.6143990159034729\n",
      "Epoch 2, Loss: 0.6115407943725586\n",
      "Epoch 2, Loss: 0.6461624503135681\n",
      "Epoch 2, Loss: 0.5271772742271423\n",
      "Epoch 2, Loss: 0.6500839591026306\n",
      "Epoch 2, Loss: 0.5903772115707397\n",
      "Epoch 2, Loss: 0.5574333071708679\n",
      "Epoch 2, Loss: 0.5257557034492493\n",
      "Epoch 2, Loss: 0.6845283508300781\n",
      "Epoch 2, Loss: 0.7577692866325378\n",
      "Epoch 2, Loss: 0.5643755793571472\n",
      "Epoch 2, Loss: 0.6104522943496704\n",
      "Epoch 2, Loss: 0.5978834629058838\n",
      "Epoch 2, Loss: 0.6465945243835449\n",
      "Epoch 2, Loss: 0.6014763116836548\n",
      "Epoch 2, Loss: 0.627293586730957\n",
      "Epoch 2, Loss: 0.689500093460083\n",
      "Epoch 2, Loss: 0.6660415530204773\n",
      "Epoch 2, Loss: 0.5882210731506348\n",
      "Epoch 2, Loss: 0.5911591649055481\n",
      "Epoch 2, Loss: 0.6536337733268738\n",
      "Epoch 2, Loss: 0.5819107294082642\n",
      "Epoch 2, Loss: 0.6816500425338745\n",
      "Epoch 2, Loss: 0.6156114339828491\n",
      "Epoch 2, Loss: 0.6788684129714966\n",
      "Epoch 2, Loss: 0.6517972946166992\n",
      "Epoch 2, Loss: 0.6454588174819946\n",
      "Epoch 2, Loss: 0.5263025760650635\n",
      "Epoch 2, Loss: 0.5895501375198364\n",
      "Epoch 2, Loss: 0.5746943354606628\n",
      "Epoch 2, Loss: 0.5723675489425659\n",
      "Epoch 2, Loss: 0.5311542749404907\n",
      "Epoch 2, Loss: 0.7625297904014587\n",
      "Epoch 2, Loss: 0.5320937633514404\n",
      "Epoch 2, Loss: 0.6126776337623596\n",
      "Epoch 2, Loss: 0.5914582014083862\n",
      "Epoch 2, Loss: 0.8485663533210754\n",
      "Epoch 2, Loss: 0.5530382990837097\n",
      "Epoch 2, Loss: 0.6730467081069946\n",
      "Epoch 2, Loss: 0.6731759905815125\n",
      "Epoch 2, Loss: 0.5936988592147827\n",
      "Epoch 2, Loss: 0.6708114147186279\n",
      "Epoch 2, Loss: 0.6115156412124634\n",
      "Epoch 2, Loss: 0.6658033728599548\n",
      "Epoch 2, Loss: 0.549262285232544\n",
      "Epoch 2, Loss: 0.6724100708961487\n",
      "Epoch 2, Loss: 0.5076048374176025\n",
      "Epoch 2, Loss: 0.6110028028488159\n",
      "Epoch 2, Loss: 0.652895987033844\n",
      "Epoch 2, Loss: 0.5670555233955383\n",
      "Epoch 2, Loss: 0.5172896385192871\n",
      "Epoch 2, Loss: 0.6004687547683716\n",
      "Epoch 2, Loss: 0.4866015613079071\n",
      "Epoch 2, Loss: 0.6195309162139893\n",
      "Epoch 2, Loss: 0.6126169562339783\n",
      "Epoch 2, Loss: 0.709729015827179\n",
      "Epoch 2, Loss: 0.44832831621170044\n",
      "Epoch 2, Loss: 0.6776237487792969\n",
      "Epoch 2, Loss: 0.7028783559799194\n",
      "Epoch 2, Loss: 0.5339947938919067\n",
      "Epoch 2, Loss: 0.5500262379646301\n",
      "Epoch 2, Loss: 0.5363555550575256\n",
      "Epoch 2, Loss: 0.5483285188674927\n",
      "Epoch 2, Loss: 0.6255912184715271\n",
      "Epoch 2, Loss: 0.5490235686302185\n",
      "Epoch 2, Loss: 0.48906493186950684\n",
      "Epoch 2, Loss: 0.6109169125556946\n",
      "Epoch 2, Loss: 0.4793124794960022\n",
      "Epoch 2, Loss: 0.6218352317810059\n",
      "Epoch 2, Loss: 0.5797714591026306\n",
      "Epoch 2, Loss: 0.6153357028961182\n",
      "Epoch 2, Loss: 0.8302230834960938\n",
      "Epoch 2, Loss: 0.6042724251747131\n",
      "Epoch 2, Loss: 0.5921021699905396\n",
      "Epoch 2, Loss: 0.5281394124031067\n",
      "Epoch 2, Loss: 0.5988898873329163\n",
      "Epoch 2, Loss: 0.5978447198867798\n",
      "Epoch 2, Loss: 0.6723877191543579\n",
      "Epoch 2, Loss: 0.6266839504241943\n",
      "Epoch 2, Loss: 0.5480338931083679\n",
      "Epoch 2, Loss: 0.5871168375015259\n",
      "Epoch 2, Loss: 0.6435983180999756\n",
      "Epoch 2, Loss: 0.5395611524581909\n",
      "Epoch 2, Loss: 0.6287711262702942\n",
      "Epoch 2, Loss: 0.6765682101249695\n",
      "Epoch 2, Loss: 0.5556001663208008\n",
      "Epoch 2, Loss: 0.6682385206222534\n",
      "Epoch 2, Loss: 0.4216381907463074\n",
      "Epoch 2, Loss: 0.5308957695960999\n",
      "Epoch 2, Loss: 0.6014237403869629\n",
      "Epoch 2, Loss: 0.795404314994812\n",
      "Epoch 2, Loss: 0.7391129732131958\n",
      "Epoch 2, Loss: 0.6565195322036743\n",
      "Epoch 2, Loss: 0.6917269229888916\n",
      "Epoch 2, Loss: 0.6351423263549805\n",
      "Epoch 2, Loss: 0.6219639182090759\n",
      "Epoch 2, Loss: 0.6312938332557678\n",
      "Epoch 2, Loss: 0.6263338327407837\n",
      "Epoch 2, Loss: 0.6404855251312256\n",
      "Epoch 2, Loss: 0.615204393863678\n",
      "Epoch 2, Loss: 0.6341414451599121\n",
      "Epoch 2, Loss: 0.6424319744110107\n",
      "Epoch 2, Loss: 0.6452668905258179\n",
      "Epoch 2, Loss: 0.6521661281585693\n",
      "Epoch 2, Loss: 0.5385115146636963\n",
      "Epoch 2, Loss: 0.7284106016159058\n",
      "Epoch 2, Loss: 0.5988645553588867\n",
      "Epoch 2, Loss: 0.6298882365226746\n",
      "Epoch 2, Loss: 0.6587277054786682\n",
      "Epoch 2, Loss: 0.6547767519950867\n",
      "Epoch 2, Loss: 0.699090301990509\n",
      "Epoch 2, Loss: 0.7454453706741333\n",
      "Epoch 2, Loss: 0.6621602177619934\n",
      "Epoch 2, Loss: 0.5627120137214661\n",
      "Epoch 2, Loss: 0.6171283721923828\n",
      "Epoch 2, Loss: 0.5916610360145569\n"
     ]
    }
   ],
   "source": [
    "# Example usage of train function\n",
    "num_epochs = 2  # Set the number of epochs\n",
    "train(model, train_loader, criterion, optimizer, num_epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader, device='cpu'):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():  # No need to track gradients for evaluation\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # For binary classification, consider the output with the highest score as the prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6988\n"
     ]
    }
   ],
   "source": [
    "# Assuming you're evaluating on CPU; if you're using a GPU, set device accordingly\n",
    "device = torch.device('cpu')\n",
    "model.to(device)  # Move the model to the right device\n",
    "\n",
    "# Call the evaluation function with the test_loader\n",
    "evaluate(model, test_loader, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test against religous biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the JSON data into a dictionary\n",
    "with open('./data/religious_sent_json.json', 'r') as file:\n",
    "    religions_dict = json.load(file)\n",
    "\n",
    "RELIGOUS_SENTENCES = religions_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sentences(glove_word_index, sentences, max_length):\n",
    "    tokenized_sentences = []\n",
    "    for sentence in sentences:\n",
    "        # Split the sentence into words and tokenize\n",
    "        tokens = [glove_word_index.get(word.lower(), 0) for word in sentence.split()]\n",
    "        # Pad or truncate the sequence to max_length\n",
    "        if len(tokens) < max_length:\n",
    "            tokens += [0] * (max_length - len(tokens))  # Padding\n",
    "        else:\n",
    "            tokens = tokens[:max_length]  # Truncating\n",
    "        tokenized_sentences.append(tokens)\n",
    "    return torch.tensor(tokenized_sentences, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import softmax\n",
    "\n",
    "\n",
    "def sentence_sentiment_table(sentences, model, word_index, device):\n",
    "    model.eval()  # Ensure the model is in evaluation mode\n",
    "    frames = []\n",
    "    for religion, sentence_list in sorted(sentences.items()):\n",
    "        # Tokenize and prepare the sentences\n",
    "        tokenized_sentences = tokenize_sentences(word_index, sentence_list, MAX_ART_LEN)\n",
    "        tokenized_sentences = tokenized_sentences.to(device)  # Move to the same device as the model\n",
    "\n",
    "        with torch.no_grad():  # Do not track gradients\n",
    "            outputs = model(tokenized_sentences)\n",
    "            probabilities = softmax(outputs, dim=1)[:, 1]  # Get the probability of the second class (positive class)\n",
    "\n",
    "        for sentence, probability in zip(sentence_list, probabilities):\n",
    "            adjusted_score = probability.item()  # Convert to a Python float\n",
    "            frames.append([sentence, adjusted_score, religion])\n",
    "            \n",
    "    return pd.DataFrame(frames, columns=['Sentence', 'Sentiment Score', 'Religion'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomTransformerModel(\n",
       "  (embedding): Embedding(2196017, 300)\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=300, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=300, bias=True)\n",
       "        (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=300, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming your model and word_index are already defined and loaded\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)  # Ensure your model is on the right device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Sentence  Sentiment Score      Religion\n",
      "0                          I follow Buddha         0.369842      Buddhism\n",
      "10   Pali canon is the standard collection         0.369842      Buddhism\n",
      "20              Stupa is a sacred monument         0.369842      Buddhism\n",
      "30       Gospel was spread by the Disciple         0.369842  Christianity\n",
      "40             This is the final Atonement         0.369842  Christianity\n",
      "50                             God is Alim         0.369842         Islam\n",
      "60              I performed Hajj last year         0.369842         Islam\n",
      "70                        I visited madina         0.369842         Islam\n",
      "80                    Shalom, how are you?         0.369842       Judaism\n",
      "90                    Pentecost is a feast         0.369842       Judaism\n",
      "100                         I speak Hebrew         0.369842       Judaism\n"
     ]
    }
   ],
   "source": [
    "sentence_sentiments = sentence_sentiment_table(RELIGOUS_SENTENCES, model, glove_word_index, device)\n",
    "\n",
    "print(sentence_sentiments[::10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def plot_sentiment(data, title, scale=[-1, 1]):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Using stripplot instead of swarmplot with jitter\n",
    "    plt.subplot(121)\n",
    "    sns.stripplot(x=title[0], y=title[1], data=data, jitter=True, size=3)\n",
    "    plt.ylim(scale)\n",
    "\n",
    "    # Adding a violin plot to better visualize distributions\n",
    "    plt.subplot(122)\n",
    "    sns.violinplot(x=title[0], y=title[1], data=data, inner=None, color=\".8\")\n",
    "    sns.barplot(x=title[0], y=title[1], data=data, capsize=.1, alpha=.7)\n",
    "\n",
    "    # plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_sentiment(sentence_sentiments, ['Religion', 'Sentiment Score'], scale=[-1, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
